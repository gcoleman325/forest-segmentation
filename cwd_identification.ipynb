{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b27bcf99-27ae-486d-ae5b-9238c4d98e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "from open3d.web_visualizer import draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310a037a-70a8-4d43-ad53-526889c22340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_point_cloud(pcd):\n",
    "    pcd = pcd.voxel_down_sample(voxel_size=0.02)\n",
    "\n",
    "    radius_normal = 0.2\n",
    "    print(\"estimating normals\")\n",
    "    pcd.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = 0.5\n",
    "    print(\"computing fpfh\")\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    fpfh = np.asarray(pcd_fpfh.data).T\n",
    "    return pcd, fpfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3790fcf2-afa1-4f1d-96a4-84876f19f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_metrics(pcd):\n",
    "    print(\"estimating covariances\")\n",
    "    covs = pcd.estimate_covariances()\n",
    "    covs = np.asarray(pcd.covariances)\n",
    "\n",
    "    print(\"computing eigen-based metrics\")\n",
    "    metrics = []\n",
    "    for pt in covs:\n",
    "        eigenvalues = np.linalg.eigvals(pt)\n",
    "        e1, e2, e3 = eigenvalues\n",
    "        \n",
    "        linearity = (e1 - e2) / e1\n",
    "        planarity = (e2 - e3) / e1\n",
    "        scattering = e3 / e1\n",
    "        omnivariance = (e1 * e2 * e3) ** (1 / 3)\n",
    "        anisotropy = (e1 - e3) / e1\n",
    "        eigentropy = -(e1 * np.log(e1) + e2 * np.log(e2) + e3 * np.log(e3))\n",
    "        curvature = e3 / (e1 + e2 + e3)\n",
    "\n",
    "        metrics.append((linearity, planarity, scattering, omnivariance, anisotropy, eigentropy, curvature))\n",
    "\n",
    "    dtype = [('linearity', 'f8'), ('planarity', 'f8'), ('scattering', 'f8'), \n",
    "            ('omnivariance', 'f8'), ('anisotropy', 'f8'), ('eigentropy', 'f8'), \n",
    "            ('curvature', 'f8')]\n",
    "    \n",
    "    metrics_array = np.array(metrics, dtype=dtype)\n",
    "  \n",
    "    return np.array([tuple(row) for row in metrics_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03ea01a-2361-45c2-98c6-b588ad9ca972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pcd(pcd_path):\n",
    "    pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "    pcd, fpfh = preprocess_point_cloud(pcd)\n",
    "    cov = cov_metrics(pcd)\n",
    "    \n",
    "    cov_headers = ['linearity', 'planarity', 'scattering', 'omnivariance', 'anisotropy', 'eigentropy', 'curvature']\n",
    "    header = ['x', 'y', 'z'] + [f'feature{i}' for i in range(fpfh.shape[1])] + cov_headers\n",
    "    all_metrics = np.hstack([np.asarray(pcd.points), fpfh, cov])\n",
    "\n",
    "    metrics = pd.DataFrame(all_metrics, columns=header)\n",
    "    #metrics = metrics[metrics['z'] <= 0.25]\n",
    "    return pcd, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8abc2d92-a51e-4a66-ae77-8007209a233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multiple(folder_path):\n",
    "    all_metrics = []\n",
    "\n",
    "    paths = glob.glob(f\"{folder_path}/**/*.pcd\", recursive=True)\n",
    "    paths = [os.path.normpath(path).replace(os.sep, '/') for path in paths]\n",
    "\n",
    "    for file_ct, path in enumerate(paths, start=1):\n",
    "        pcd, metrics = prep_pcd(path)\n",
    "        metrics[\"scan_num\"] = file_ct\n",
    "        all_metrics.append(metrics)\n",
    "\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "688a2758-89bf-417e-8ca7-852b8e8b63b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimating normals\n",
      "computing fpfh\n",
      "estimating covariances\n",
      "computing eigen-based metrics\n",
      "estimating normals\n",
      "computing fpfh\n",
      "estimating covariances\n",
      "computing eigen-based metrics\n",
      "estimating normals\n",
      "computing fpfh\n",
      "estimating covariances\n",
      "computing eigen-based metrics\n"
     ]
    }
   ],
   "source": [
    "scans = process_multiple(\"C:/Users/ellie/OneDrive/Desktop/lidar_local/ccb_no_trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a0c2fe0-3e04-4e9f-bea0-a6b2fa7a8219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3106080, 44)\n",
      "(3106080, 3)\n",
      "(3106080, 41)\n",
      "(3106080, 41)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "scans_full = np.vstack((scans[0], scans[1]))\n",
    "scans_full = np.vstack((scans_full, scans[2]))\n",
    "\n",
    "scans_full_aboveZ = scans_full#[scans_full[:, 2] > 0.025]\n",
    "print(pd.DataFrame(scans_full_aboveZ).shape)\n",
    "coords = scans_full_aboveZ[:, :3]\n",
    "print(pd.DataFrame(coords, columns=['x','y','z']).shape)\n",
    "coords_scan = np.concatenate([coords, scans_full_aboveZ[:, -1].reshape(-1, 1)], axis=1)\n",
    "features = scans_full_aboveZ[:, 3:]\n",
    "print(features.shape)\n",
    "\n",
    "scaled_features = pipeline.fit_transform(features)\n",
    "print(scaled_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffbaf3a5-e79f-4116-9c05-0bc6021fd4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m ks:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(k)\n\u001b[1;32m---> 10\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     errors[k] \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39minertia_\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kmeans\u001b[38;5;241m.\u001b[39minertia_ \u001b[38;5;241m<\u001b[39m min_inertia:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1519\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[1;32m-> 1519\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[0;32m   1532\u001b[0m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1535\u001b[0m     inertia \u001b[38;5;241m<\u001b[39m best_inertia\n\u001b[0;32m   1536\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[0;32m   1537\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:162\u001b[0m, in \u001b[0;36m_threadpool_controller_decorator.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m controller \u001b[38;5;241m=\u001b[39m _get_threadpool_controller()\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api):\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:707\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[1;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[0;32m    704\u001b[0m strict_convergence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m--> 707\u001b[0m     \u001b[43mlloyd_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenters_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_in_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcenter_shift\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    719\u001b[0m         inertia \u001b[38;5;241m=\u001b[39m _inertia(X, sample_weight, centers, labels, n_threads)\n",
      "File \u001b[1;32m_k_means_lloyd.pyx:160\u001b[0m, in \u001b[0;36msklearn.cluster._k_means_lloyd.lloyd_iter_chunked_dense\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_k_means_common.pyx:180\u001b[0m, in \u001b[0;36msklearn.cluster._k_means_common._relocate_empty_clusters_dense\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "coords_scan_df = pd.DataFrame(coords_scan, columns=['x','y','z', 'scan'])\n",
    "ks = [2, 3, 4, 5, 6, 7]\n",
    "errors = {}\n",
    "min_inertia = 2**1000\n",
    "optimal_k = 0\n",
    "for k in ks:\n",
    "    print(k)\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init=\"auto\").fit(scaled_features)\n",
    "    errors[k] = kmeans.inertia_\n",
    "    if kmeans.inertia_ < min_inertia:\n",
    "        min_inertia = kmeans.inertia_\n",
    "        optimal_k = k\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0, n_init=\"auto\").fit(scaled_features)\n",
    "coords_scan_df['cluster'] = kmeans.labels_\n",
    "print(coords_scan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580ef5d-f323-4c13-9548-b608bfb6eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ks = list(errors.keys())\n",
    "sse_values = list(errors.values())\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(ks, sse_values, marker='o', linestyle='-', color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cd3fb96-0519-4bd0-a9b7-35bcb543d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(scaled_features)\n",
    "coords_scan_df['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b916d44-9510-44a0-a196-5148826838f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_1 = coords_scan_df[np.isclose(coords_scan_df.iloc[:, 3], 1.0)]\n",
    "just_clusters = scan_1[[\"x\", \"y\", \"z\", \"cluster\"]]\n",
    "#just_clusters = just_clusters[just_clusters['z']<0.3]\n",
    "\n",
    "for i in range(5):  # Handle up to 5 clusters or the number of found clusters\n",
    "    cluster_points = just_clusters[just_clusters['cluster'] == i][['x', 'y', 'z']].values\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cluster_points)\n",
    "    o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99a0065-bf34-4d9a-aff2-6479a30d92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=10, min_samples=100000).fit(scaled_features)\n",
    "coords_scan_df['cluster'] = dbscan.labels_\n",
    "scan_1 = coords_scan_df[np.isclose(coords_scan_df.iloc[:, 3], 3.0)]\n",
    "just_clusters = scan_1[[\"x\", \"y\", \"z\", \"cluster\"]]\n",
    "#just_clusters = just_clusters[just_clusters['z']<0.3]\n",
    "\n",
    "for i in range(5):  # Handle up to 5 clusters or the number of found clusters\n",
    "    cluster_points = just_clusters[just_clusters['cluster'] == i][['x', 'y', 'z']].values\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(cluster_points)\n",
    "    o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd32a69-f1f4-44a8-9835-16e2bc4c7c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
